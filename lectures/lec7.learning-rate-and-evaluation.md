# Lecture 7: learning rate and evaluation

- learning rate(alpha, a)는 학습률로 학습의 스텝 크기를 조절하는 하이퍼파라미터. 이 값이 너무 커지면, cost가 발산하여 overshooting되고, 값이 너무 작으면, cost가 최적값에 도달하는 데에 너무 오랜 시간이 걸림. 0.01, 0.001 등의 값을 시도한 뒤, cost를 모니터링하여 조절해주어야 함.
- 가끔, 학습률을 조정하여도 cost가 inf, nan 등으로 측정될 때가 있음. 이는 데이터에서 컬럼 간 scaling이 잘 되어 있지 않아, 발생할 수 있는 문제임. 데이터 처리 과정에서 min-max scaling(0~1) 또는 Standardization(평균 0, 표준편차 1)하여 해소해볼 수 있음. 
- Overfitting: 오버피팅은 모델이 학습 데이터에는 매우 적합하나, 그 외 데이터에 대해서는 매우 낮은 성능을 보이는 것을 말함. 즉, 기억에만 의존하는, 일반화되지 않은 모델이라고 할 수 있음. 
- 오버피팅 해소 방법: 1) 학습 데이터를 더 늘린다 2) 특징의 수를 줄인다 3) Regularization (정규화) 오버피팅이 발생하는 경우, 특징 x1, x2, x3에 대한 가중치 w1, w2, w3의 값이 매우 큰 폭으로 차이날 수 있음. 이에 제약을 걸기 위하여, 가중치 자체의 값이 커지지 않게 cost에 가중치 정규화항을 추가하는 방법도 있음
- 모델은 어떻게 평가하는가? 데이터를 train/ val/ test 세트로 나누어 학습에는 training set만 사용하고 validation set은 하이퍼파라미터 튜닝에, test set는 모델의 성능을 평가할 때 사용하면 학습에 사용하지 않은 데이터로 성능을 평가하는 것이 된다.