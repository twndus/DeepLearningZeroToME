{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 09: XOR problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array([\n",
    "    [1, 1],\n",
    "    [0, 0],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "], dtype='float32')\n",
    "\n",
    "y_data = np.array([\n",
    "    [0],\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_w = tf.random.normal(shape=(2,1), dtype='float32')\n",
    "rand_b = tf.random.normal(shape=(1,), dtype='float32')\n",
    "\n",
    "w = tf.Variable(rand_w, dtype='float32')\n",
    "b = tf.Variable(rand_b, dtype='float32')\n",
    "\n",
    "hypothesis = lambda x, w, b: tf.matmul(x, w) + b\n",
    "loss = lambda hypothesis,y : tf.reduce_sum(tf.square(hypothesis - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 cost:  1.8681388 accuracy:  0.75\n",
      "epoch:  1 cost:  1.7323489 accuracy:  0.75\n",
      "epoch:  2 cost:  1.6263412 accuracy:  0.75\n",
      "epoch:  3 cost:  1.5431064 accuracy:  0.75\n",
      "epoch:  4 cost:  1.4773057 accuracy:  0.75\n",
      "epoch:  5 cost:  1.4248692 accuracy:  0.75\n",
      "epoch:  6 cost:  1.3826956 accuracy:  0.75\n",
      "epoch:  7 cost:  1.3484205 accuracy:  0.75\n",
      "epoch:  8 cost:  1.32024 accuracy:  0.75\n",
      "epoch:  9 cost:  1.296778 accuracy:  0.75\n",
      "epoch:  10 cost:  1.2769837 accuracy:  0.5\n",
      "epoch:  11 cost:  1.2600539 accuracy:  0.5\n",
      "epoch:  12 cost:  1.2453749 accuracy:  0.5\n",
      "epoch:  13 cost:  1.2324762 accuracy:  0.5\n",
      "epoch:  14 cost:  1.2209976 accuracy:  0.5\n",
      "epoch:  15 cost:  1.2106618 accuracy:  0.5\n",
      "epoch:  16 cost:  1.2012559 accuracy:  0.5\n",
      "epoch:  17 cost:  1.1926153 accuracy:  0.5\n",
      "epoch:  18 cost:  1.1846123 accuracy:  0.5\n",
      "epoch:  19 cost:  1.1771479 accuracy:  0.5\n",
      "epoch:  20 cost:  1.1701444 accuracy:  0.5\n",
      "epoch:  21 cost:  1.1635411 accuracy:  0.5\n",
      "epoch:  22 cost:  1.1572897 accuracy:  0.5\n",
      "epoch:  23 cost:  1.1513515 accuracy:  0.5\n",
      "epoch:  24 cost:  1.1456956 accuracy:  0.5\n",
      "epoch:  25 cost:  1.1402965 accuracy:  0.5\n",
      "epoch:  26 cost:  1.1351334 accuracy:  0.5\n",
      "epoch:  27 cost:  1.130189 accuracy:  0.5\n",
      "epoch:  28 cost:  1.1254483 accuracy:  0.5\n",
      "epoch:  29 cost:  1.120899 accuracy:  0.5\n",
      "epoch:  30 cost:  1.11653 accuracy:  0.5\n",
      "epoch:  31 cost:  1.1123316 accuracy:  0.5\n",
      "epoch:  32 cost:  1.1082952 accuracy:  0.5\n",
      "epoch:  33 cost:  1.1044132 accuracy:  0.5\n",
      "epoch:  34 cost:  1.1006782 accuracy:  0.5\n",
      "epoch:  35 cost:  1.0970837 accuracy:  0.5\n",
      "epoch:  36 cost:  1.0936239 accuracy:  0.5\n",
      "epoch:  37 cost:  1.0902932 accuracy:  0.5\n",
      "epoch:  38 cost:  1.0870862 accuracy:  0.5\n",
      "epoch:  39 cost:  1.0839977 accuracy:  0.5\n",
      "epoch:  40 cost:  1.0810235 accuracy:  0.5\n",
      "epoch:  41 cost:  1.0781585 accuracy:  0.5\n",
      "epoch:  42 cost:  1.0753989 accuracy:  0.5\n",
      "epoch:  43 cost:  1.0727406 accuracy:  0.5\n",
      "epoch:  44 cost:  1.0701795 accuracy:  0.5\n",
      "epoch:  45 cost:  1.0677122 accuracy:  0.5\n",
      "epoch:  46 cost:  1.0653348 accuracy:  0.5\n",
      "epoch:  47 cost:  1.0630441 accuracy:  0.5\n",
      "epoch:  48 cost:  1.0608369 accuracy:  0.5\n",
      "epoch:  49 cost:  1.0587099 accuracy:  0.5\n",
      "epoch:  50 cost:  1.05666 accuracy:  0.5\n",
      "epoch:  51 cost:  1.0546846 accuracy:  0.5\n",
      "epoch:  52 cost:  1.0527806 accuracy:  0.5\n",
      "epoch:  53 cost:  1.0509456 accuracy:  0.5\n",
      "epoch:  54 cost:  1.0491769 accuracy:  0.5\n",
      "epoch:  55 cost:  1.0474721 accuracy:  0.5\n",
      "epoch:  56 cost:  1.0458288 accuracy:  0.5\n",
      "epoch:  57 cost:  1.0442445 accuracy:  0.5\n",
      "epoch:  58 cost:  1.0427173 accuracy:  0.5\n",
      "epoch:  59 cost:  1.0412451 accuracy:  0.5\n",
      "epoch:  60 cost:  1.0398254 accuracy:  0.5\n",
      "epoch:  61 cost:  1.0384569 accuracy:  0.5\n",
      "epoch:  62 cost:  1.0371373 accuracy:  0.5\n",
      "epoch:  63 cost:  1.0358648 accuracy:  0.5\n",
      "epoch:  64 cost:  1.0346378 accuracy:  0.5\n",
      "epoch:  65 cost:  1.0334547 accuracy:  0.5\n",
      "epoch:  66 cost:  1.0323135 accuracy:  0.5\n",
      "epoch:  67 cost:  1.031213 accuracy:  0.5\n",
      "epoch:  68 cost:  1.0301517 accuracy:  0.5\n",
      "epoch:  69 cost:  1.029128 accuracy:  0.5\n",
      "epoch:  70 cost:  1.0281405 accuracy:  0.5\n",
      "epoch:  71 cost:  1.0271881 accuracy:  0.5\n",
      "epoch:  72 cost:  1.0262694 accuracy:  0.5\n",
      "epoch:  73 cost:  1.025383 accuracy:  0.5\n",
      "epoch:  74 cost:  1.024528 accuracy:  0.5\n",
      "epoch:  75 cost:  1.0237031 accuracy:  0.5\n",
      "epoch:  76 cost:  1.022907 accuracy:  0.5\n",
      "epoch:  77 cost:  1.0221391 accuracy:  0.5\n",
      "epoch:  78 cost:  1.0213981 accuracy:  0.5\n",
      "epoch:  79 cost:  1.0206829 accuracy:  0.5\n",
      "epoch:  80 cost:  1.019993 accuracy:  0.5\n",
      "epoch:  81 cost:  1.0193269 accuracy:  0.5\n",
      "epoch:  82 cost:  1.0186844 accuracy:  0.5\n",
      "epoch:  83 cost:  1.0180639 accuracy:  0.5\n",
      "epoch:  84 cost:  1.0174652 accuracy:  0.5\n",
      "epoch:  85 cost:  1.0168873 accuracy:  0.5\n",
      "epoch:  86 cost:  1.0163294 accuracy:  0.5\n",
      "epoch:  87 cost:  1.0157909 accuracy:  0.5\n",
      "epoch:  88 cost:  1.0152708 accuracy:  0.5\n",
      "epoch:  89 cost:  1.0147688 accuracy:  0.5\n",
      "epoch:  90 cost:  1.0142843 accuracy:  0.5\n",
      "epoch:  91 cost:  1.0138164 accuracy:  0.5\n",
      "epoch:  92 cost:  1.0133643 accuracy:  0.5\n",
      "epoch:  93 cost:  1.012928 accuracy:  0.5\n",
      "epoch:  94 cost:  1.0125067 accuracy:  0.5\n",
      "epoch:  95 cost:  1.0120997 accuracy:  0.5\n",
      "epoch:  96 cost:  1.0117066 accuracy:  0.5\n",
      "epoch:  97 cost:  1.011327 accuracy:  0.5\n",
      "epoch:  98 cost:  1.0109603 accuracy:  0.5\n",
      "epoch:  99 cost:  1.010606 accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "for e in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = hypothesis(x_data, w, b)\n",
    "        cost = loss(logits, y_data)\n",
    "        dl_dw, dl_db = tape.gradient(cost, [w,b])\n",
    "    w.assign_sub(learning_rate*dl_dw)\n",
    "    b.assign_sub(learning_rate*dl_db)\n",
    "\n",
    "    print(\"epoch: \", e, \"cost: \", cost.numpy(), \"accuracy: \", accuracy_score(y_data, logits>=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "거듭 학습해도, 정확도는 0.5에서 좋아지지 않음    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여러 층을 쌓아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
       " array([[-8., -8.],\n",
       "        [-5., -5.]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(2,) dtype=float32, numpy=array([5., 8.], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
       " array([[-5.],\n",
       "        [-5.]], dtype=float32)>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=8.0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_W1 = tf.random.uniform(shape=(2,2), dtype='float32')\n",
    "rand_b1 = tf.random.uniform(shape=(2,), dtype='float32')\n",
    "\n",
    "rand_W2 = tf.random.uniform(shape=(2,1), dtype='float32')\n",
    "rand_b2 = tf.random.uniform(shape=(1,), dtype='float32')\n",
    "\n",
    "# W1 = tf.Variable(rand_W1, dtype='float32')\n",
    "# b1 = tf.Variable(rand_b1, dtype='float32')\n",
    "\n",
    "# W2 = tf.Variable(rand_W2, dtype='float32')\n",
    "# b2 = tf.Variable(rand_b2, dtype='float32')\n",
    "\n",
    "W1 = tf.Variable(((-8,-8), (-5,-5)), dtype='float32')\n",
    "b1 = tf.Variable((5, 8), dtype='float32')\n",
    "\n",
    "W2 = tf.Variable(((-5,), (-5,)), dtype='float32')\n",
    "b2 = tf.Variable((8), dtype='float32')\n",
    "\n",
    "hypothesis = lambda x, w, b: tf.matmul(x, w) + b\n",
    "loss = lambda hypothesis, y : tf.reduce_sum(tf.square(hypothesis - y))\n",
    "\n",
    "# rand_W1, rand_b1, rand_W2, rand_b2\n",
    "W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 cost:  9126.0 accuracy:  0.5\n",
      "epoch:  1 cost:  2847.1553 accuracy:  0.5\n",
      "epoch:  2 cost:  1380.874 accuracy:  0.5\n",
      "epoch:  3 cost:  758.09705 accuracy:  0.5\n",
      "epoch:  4 cost:  460.42035 accuracy:  0.5\n",
      "epoch:  5 cost:  308.91373 accuracy:  0.75\n",
      "epoch:  6 cost:  227.69238 accuracy:  0.75\n",
      "epoch:  7 cost:  181.40234 accuracy:  0.75\n",
      "epoch:  8 cost:  152.8109 accuracy:  0.75\n",
      "epoch:  9 cost:  133.33836 accuracy:  0.75\n",
      "epoch:  10 cost:  118.67421 accuracy:  0.75\n",
      "epoch:  11 cost:  106.64736 accuracy:  0.75\n",
      "epoch:  12 cost:  96.16717 accuracy:  0.75\n",
      "epoch:  13 cost:  86.690544 accuracy:  0.75\n",
      "epoch:  14 cost:  77.95239 accuracy:  0.5\n",
      "epoch:  15 cost:  69.82837 accuracy:  0.5\n",
      "epoch:  16 cost:  62.26439 accuracy:  0.5\n",
      "epoch:  17 cost:  55.24001 accuracy:  0.5\n",
      "epoch:  18 cost:  48.74901 accuracy:  0.5\n",
      "epoch:  19 cost:  42.789165 accuracy:  0.5\n",
      "epoch:  20 cost:  37.356533 accuracy:  0.75\n",
      "epoch:  21 cost:  32.44273 accuracy:  0.75\n",
      "epoch:  22 cost:  28.033655 accuracy:  0.75\n",
      "epoch:  23 cost:  24.10937 accuracy:  0.75\n",
      "epoch:  24 cost:  20.644566 accuracy:  0.75\n",
      "epoch:  25 cost:  17.60956 accuracy:  0.75\n",
      "epoch:  26 cost:  14.97142 accuracy:  0.75\n",
      "epoch:  27 cost:  12.695122 accuracy:  0.75\n",
      "epoch:  28 cost:  10.744896 accuracy:  0.75\n",
      "epoch:  29 cost:  9.085193 accuracy:  0.75\n",
      "epoch:  30 cost:  7.681634 accuracy:  0.75\n",
      "epoch:  31 cost:  6.501685 accuracy:  0.75\n",
      "epoch:  32 cost:  5.5151725 accuracy:  0.75\n",
      "epoch:  33 cost:  4.694588 accuracy:  0.75\n",
      "epoch:  34 cost:  4.01521 accuracy:  0.75\n",
      "epoch:  35 cost:  3.4551847 accuracy:  0.75\n",
      "epoch:  36 cost:  2.9953635 accuracy:  0.75\n",
      "epoch:  37 cost:  2.6191695 accuracy:  0.75\n",
      "epoch:  38 cost:  2.3124013 accuracy:  0.75\n",
      "epoch:  39 cost:  2.0629847 accuracy:  0.75\n",
      "epoch:  40 cost:  1.8607256 accuracy:  0.75\n",
      "epoch:  41 cost:  1.6971039 accuracy:  0.75\n",
      "epoch:  42 cost:  1.5650158 accuracy:  0.75\n",
      "epoch:  43 cost:  1.4585812 accuracy:  0.75\n",
      "epoch:  44 cost:  1.3729489 accuracy:  0.75\n",
      "epoch:  45 cost:  1.3041596 accuracy:  0.75\n",
      "epoch:  46 cost:  1.248955 accuracy:  0.5\n",
      "epoch:  47 cost:  1.2046931 accuracy:  0.5\n",
      "epoch:  48 cost:  1.1692317 accuracy:  0.5\n",
      "epoch:  49 cost:  1.1408346 accuracy:  0.5\n",
      "epoch:  50 cost:  1.1180985 accuracy:  0.5\n",
      "epoch:  51 cost:  1.0998898 accuracy:  0.5\n",
      "epoch:  52 cost:  1.0853055 accuracy:  0.25\n",
      "epoch:  53 cost:  1.0736115 accuracy:  0.25\n",
      "epoch:  54 cost:  1.0642269 accuracy:  0.25\n",
      "epoch:  55 cost:  1.0566833 accuracy:  0.25\n",
      "epoch:  56 cost:  1.0506053 accuracy:  0.25\n",
      "epoch:  57 cost:  1.045697 accuracy:  0.25\n",
      "epoch:  58 cost:  1.0417203 accuracy:  0.25\n",
      "epoch:  59 cost:  1.0384815 accuracy:  0.25\n",
      "epoch:  60 cost:  1.0358331 accuracy:  0.25\n",
      "epoch:  61 cost:  1.0336566 accuracy:  0.25\n",
      "epoch:  62 cost:  1.0318518 accuracy:  0.25\n",
      "epoch:  63 cost:  1.0303442 accuracy:  0.25\n",
      "epoch:  64 cost:  1.0290747 accuracy:  0.25\n",
      "epoch:  65 cost:  1.0279953 accuracy:  0.25\n",
      "epoch:  66 cost:  1.0270643 accuracy:  0.25\n",
      "epoch:  67 cost:  1.0262568 accuracy:  0.25\n",
      "epoch:  68 cost:  1.0255432 accuracy:  0.25\n",
      "epoch:  69 cost:  1.0249093 accuracy:  0.25\n",
      "epoch:  70 cost:  1.024339 accuracy:  0.25\n",
      "epoch:  71 cost:  1.0238166 accuracy:  0.5\n",
      "epoch:  72 cost:  1.0233383 accuracy:  0.5\n",
      "epoch:  73 cost:  1.0228913 accuracy:  0.5\n",
      "epoch:  74 cost:  1.0224729 accuracy:  0.5\n",
      "epoch:  75 cost:  1.0220795 accuracy:  0.5\n",
      "epoch:  76 cost:  1.0217004 accuracy:  0.5\n",
      "epoch:  77 cost:  1.0213399 accuracy:  0.5\n",
      "epoch:  78 cost:  1.0209937 accuracy:  0.5\n",
      "epoch:  79 cost:  1.0206554 accuracy:  0.5\n",
      "epoch:  80 cost:  1.0203326 accuracy:  0.5\n",
      "epoch:  81 cost:  1.0200163 accuracy:  0.5\n",
      "epoch:  82 cost:  1.0197067 accuracy:  0.5\n",
      "epoch:  83 cost:  1.0194063 accuracy:  0.5\n",
      "epoch:  84 cost:  1.0191107 accuracy:  0.5\n",
      "epoch:  85 cost:  1.018821 accuracy:  0.5\n",
      "epoch:  86 cost:  1.018539 accuracy:  0.5\n",
      "epoch:  87 cost:  1.0182608 accuracy:  0.5\n",
      "epoch:  88 cost:  1.0179868 accuracy:  0.5\n",
      "epoch:  89 cost:  1.017719 accuracy:  0.5\n",
      "epoch:  90 cost:  1.0174549 accuracy:  0.5\n",
      "epoch:  91 cost:  1.0171951 accuracy:  0.5\n",
      "epoch:  92 cost:  1.0169375 accuracy:  0.5\n",
      "epoch:  93 cost:  1.016686 accuracy:  0.5\n",
      "epoch:  94 cost:  1.0164384 accuracy:  0.5\n",
      "epoch:  95 cost:  1.0161954 accuracy:  0.5\n",
      "epoch:  96 cost:  1.0159554 accuracy:  0.5\n",
      "epoch:  97 cost:  1.0157173 accuracy:  0.5\n",
      "epoch:  98 cost:  1.0154853 accuracy:  0.5\n",
      "epoch:  99 cost:  1.0152549 accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "for e in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        l1_output = hypothesis(x_data, W1, b1)\n",
    "        l2_output = hypothesis(l1_output, W2, b2)\n",
    "        cost = loss(l2_output, y_data)\n",
    "        dl_dW1, dl_db1, dl_dW2, dl_db2 = tape.gradient(cost, [W1,b1,W2,b2])\n",
    "    # L1 update\n",
    "    W1.assign_sub(learning_rate*dl_dW1)\n",
    "    b1.assign_sub(learning_rate*dl_db1)\n",
    "    # L2 update\n",
    "    W2.assign_sub(learning_rate*dl_dW2)\n",
    "    b2.assign_sub(learning_rate*dl_db2)\n",
    "\n",
    "    print(\"epoch: \", e, \"cost: \", cost.numpy(), \"accuracy: \", accuracy_score(y_data, l2_output>=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
